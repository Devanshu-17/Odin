{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "IzFOyK8bzpIM"
   },
   "outputs": [],
   "source": [
    "!unzip abc.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "o56bwq2NzsI3"
   },
   "outputs": [],
   "source": [
    "%cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cE7v_nCNyWjB",
    "outputId": "6c1d2776-50bb-45ee-e078-152ce44c1412"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-692d0f4d61ff>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  images = np.array(images)\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_49 (Conv2D)          (None, 28, 28, 75)        750       \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 28, 28, 75)       300       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPoolin  (None, 14, 14, 75)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 14, 14, 50)        33800     \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 14, 14, 50)       200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 7, 7, 50)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 7, 7, 25)          11275     \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 7, 7, 25)         100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 4, 4, 25)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 32)                12832     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 60)                1980      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,237\n",
      "Trainable params: 60,937\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "def load_images_labels(images_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(images_folder):\n",
    "        if filename.endswith('.jpeg') or filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image = cv2.imread(os.path.join(images_folder, filename))\n",
    "            images.append(image)\n",
    "            label = filename.split('.')[0]\n",
    "            labels.append(label)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Load the images and labels from the folders\n",
    "train_images, train_labels = load_images_labels('/content/Train')\n",
    "test_images, test_labels = load_images_labels('/content/Test')\n",
    "\n",
    "# Preprocessing the images to be ready for the model\n",
    "train_images = np.array([cv2.resize(image, (224, 224)) for image in train_images])\n",
    "test_images = np.array([cv2.resize(image, (224, 224)) for image in test_images])\n",
    "\n",
    "# One hot encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "train_labels = onehot_encoder.fit_transform(train_labels.reshape(-1, 1)).toarray()\n",
    "test_labels = onehot_encoder.transform(test_labels.reshape(-1, 1)).toarray()\n",
    "\n",
    "# Load the pre-trained model and freeze its layers\n",
    "vgg = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new layers on top of the pre-trained model\n",
    "x = vgg.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=vgg.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x=train_images, y=train_labels, batch_size=32, epochs=50, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
